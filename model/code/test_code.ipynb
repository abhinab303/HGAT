{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import numpy as np\n",
    "from utils import load_data\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/Abhinab/HGAT/code/HGAT/model/data/agnews/\"\n",
    "dataset = 'agnews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "423it [00:00, 4106.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading agnews dataset...\n",
      "Loading text content...\n",
      "E:/Abhinab/HGAT/code/HGAT/model/data/agnews/\n",
      "agnews\n",
      "text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [00:01, 5105.70it/s]\n",
      "E:\\Abhinab\\HGAT\\code\\HGAT\\model\\code\\utils.py:208: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "20it [00:00, 606.07it/s]\n",
      "105it [00:00, 1039.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label matrix shape: torch.Size([6000, 4])\n",
      "done.\n",
      "Loading topic content...\n",
      "E:/Abhinab/HGAT/code/HGAT/model/data/agnews/\n",
      "agnews\n",
      "topic\n",
      "done.\n",
      "Loading entity content...\n",
      "E:/Abhinab/HGAT/code/HGAT/model/data/agnews/\n",
      "agnews\n",
      "entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3907it [00:03, 1287.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Building graph...\n",
      "Num of edges: 209847\n",
      "train, vali, test:  1600 1600 2800\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train_ori, idx_val_ori, idx_test_ori, idx_map = load_data(path = path, dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.sparse.FloatTensor'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[0][0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([6000, 626]), torch.Size([20, 626]), torch.Size([3907, 2785])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: \n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.]])\n",
      "method 1: \n",
      "tensor([[ 4.,  4.,  4.,  4.],\n",
      "        [ 8.,  8.,  8.,  8.],\n",
      "        [12., 12., 12., 12.]])\n",
      "method 2: \n",
      "tensor([[ 4.,  4.,  4.,  4.],\n",
      "        [ 8.,  8.,  8.,  8.],\n",
      "        [12., 12., 12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "test_adj = torch.Tensor([[1, 2, 3]]).t().repeat(1, 4)\n",
    "print(\"A: \")\n",
    "print(test_adj)\n",
    "print(\"method 1: \")\n",
    "print(test_adj.sum(1).repeat(4, 1).t())\n",
    "print(\"method 2: \")\n",
    "print(th.mm(test_adj, th.ones(4, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0000e+15, -9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(test_adj > 1, torch.ones_like(test_adj), -9e15*torch.ones_like(test_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.0900, 0.0900, 0.0900],\n",
       "        [0.2447, 0.2447, 0.2447, 0.2447],\n",
       "        [0.6652, 0.6652, 0.6652, 0.6652]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(test_adj, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((th.tensor([1., 2., 3.]),), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack test\n",
    "xt_1 = [th.tensor([1., 2., 3., 4.]), th.tensor([1., 2., 3., 4.]), th.tensor([1., 2., 3., 4.])]\n",
    "torch.stack(xt_1, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6000, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack test 2\n",
    "# x = torch.cat([x, torch.stack([x[self.idx]] * self.n, dim=0)], dim=2)\n",
    "x = torch.rand(6000, 3, 50)\n",
    "x = x.transpose(0, 1)\n",
    "n = x.size()[0]\n",
    "# torch.stack([x[0]] * n, dim=0).shape\n",
    "torch.cat([x, torch.stack([x[0]] * n, dim=0)], dim=2).shape\n",
    "# len([x[0]] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6000, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch multiplication test\n",
    "x = torch.rand(3, 6000, 100)\n",
    "a = torch.rand(100, 1)\n",
    "# torch.matmul(x, a).shape\n",
    "F.leaky_relu_(torch.matmul(x, a)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch multiplication test 2\n",
    "weights = torch.rand(6000, 3, 1)\n",
    "inputs = torch.rand(6000, 3, 512)\n",
    "(torch.matmul(weights.transpose(1, 2), inputs).squeeze(1)*3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HGAT model loading:\n",
    "from models import HGAT\n",
    "\n",
    "model = HGAT(nfeat_list=[i.shape[1] for i in features],\n",
    "                    type_attention = True,\n",
    "                    node_attention = True,\n",
    "                    nhid=512,\n",
    "                    nclass=labels.shape[1],\n",
    "                    dropout=0.5,\n",
    "                    gamma=0.1,\n",
    "                    orphan=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-2.5089, -2.0249, -1.8353, -1.3351, -2.8303, -1.1876],\n",
       "         [-2.6877, -1.9871, -2.0454, -1.3810, -2.8728, -1.0281],\n",
       "         [-2.5822, -1.9165, -1.7132, -1.4914, -2.9023, -1.1487],\n",
       "         ...,\n",
       "         [-2.8009, -1.7958, -1.6703, -1.5745, -2.9919, -1.1155],\n",
       "         [-3.0405, -1.5190, -1.6627, -1.6723, -2.8416, -1.2124],\n",
       "         [-2.6721, -1.7791, -1.6616, -1.6078, -2.7571, -1.1762]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[ -1.8333,  -5.3801,  -2.3834,  -0.6439, -11.7857,  -1.5230],\n",
       "         [ -2.0219,  -3.8736,  -1.6384,  -0.9988,  -7.7968,  -1.2595],\n",
       "         [ -1.7271,  -3.5366,  -1.8998,  -0.9216,  -7.0563,  -1.4076],\n",
       "         [ -1.9014,  -3.8579,  -2.0391,  -0.9818,  -7.7670,  -1.1260],\n",
       "         [ -2.1387,  -3.7785,  -2.0978,  -0.9289,  -7.4695,  -1.0756],\n",
       "         [ -2.0758,  -3.8195,  -1.9161,  -0.9504,  -6.8066,  -1.1466],\n",
       "         [ -1.8104,  -3.5515,  -1.8291,  -0.8373,  -6.5199,  -1.5473],\n",
       "         [ -1.7476,  -3.3436,  -1.6188,  -0.9128,  -6.2517,  -1.6657],\n",
       "         [ -1.8473,  -3.8522,  -1.8794,  -0.9699,  -7.5104,  -1.2422],\n",
       "         [ -1.8087,  -3.8829,  -1.9679,  -1.1254,  -6.9289,  -1.0490],\n",
       "         [ -2.0439,  -5.6933,  -2.1574,  -0.6694, -10.3144,  -1.4294],\n",
       "         [ -2.2404,  -4.1405,  -1.7020,  -0.9913,  -7.3635,  -1.1282],\n",
       "         [ -1.9517,  -3.6266,  -1.5157,  -1.0465,  -7.3263,  -1.3476],\n",
       "         [ -1.7345,  -3.2154,  -1.8276,  -1.0905,  -5.1392,  -1.2706],\n",
       "         [ -2.2980,  -3.8851,  -1.7769,  -1.0619,  -7.5716,  -1.0119],\n",
       "         [ -2.3118,  -3.4663,  -1.7808,  -0.8770,  -6.2477,  -1.2615],\n",
       "         [ -2.2750,  -3.8861,  -2.3026,  -0.8206,  -7.7602,  -1.0904],\n",
       "         [ -1.6466,  -5.4331,  -2.5129,  -0.9569, -11.3546,  -1.0853],\n",
       "         [ -2.3844,  -3.8616,  -1.7561,  -1.1619,  -6.6173,  -0.9166],\n",
       "         [ -1.3915,  -3.8541,  -1.7008,  -1.6017,  -8.3785,  -1.0619]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[-2.2967, -1.9113, -1.7360, -1.4496, -2.5515, -1.3369],\n",
       "         [-2.3713, -1.8123, -1.6792, -1.4985, -2.6408, -1.3391],\n",
       "         [-2.2669, -1.8787, -1.6729, -1.4749, -2.6226, -1.3686],\n",
       "         ...,\n",
       "         [-2.3235, -2.0391, -1.5860, -1.5082, -2.3715, -1.3763],\n",
       "         [-2.3862, -1.8011, -1.6936, -1.5388, -2.5277, -1.3296],\n",
       "         [-2.2644, -1.8048, -1.6734, -1.4919, -2.5372, -1.4272]],\n",
       "        grad_fn=<LogSoftmaxBackward>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(features, adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
